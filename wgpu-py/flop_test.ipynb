{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15804ca0-bea9-4d9d-bade-e167c216757b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wgpu\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "import math\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9b85911-5d40-4dda-9f54-89f67bb9db55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'adapter_type': 'IntegratedGPU',\n",
      " 'architecture': '',\n",
      " 'backend_type': 'Vulkan',\n",
      " 'description': '24.12.1 (AMD proprietary shader compiler)',\n",
      " 'device': 'AMD Radeon(TM) Graphics',\n",
      " 'device_id': 5761,\n",
      " 'vendor': 'AMD proprietary driver',\n",
      " 'vendor_id': 4098}\n",
      "{'adapter_type': 'IntegratedGPU',\n",
      " 'architecture': '',\n",
      " 'backend_type': 'Vulkan',\n",
      " 'description': '24.12.1 (AMD proprietary shader compiler)',\n",
      " 'device': 'AMD Radeon(TM) Graphics',\n",
      " 'device_id': 5761,\n",
      " 'vendor': 'AMD proprietary driver',\n",
      " 'vendor_id': 4098}\n"
     ]
    }
   ],
   "source": [
    "adapter_0 = wgpu.gpu.request_adapter_sync(power_preference=\"high-performance\")\n",
    "device_0 = adapter_0.request_device_sync(\n",
    "    required_features=[wgpu.FeatureName.timestamp_query]\n",
    ")\n",
    "pprint(adapter_0.info)\n",
    "\n",
    "adapter_1 = wgpu.gpu.request_adapter_sync(power_preference=\"low-power\")\n",
    "device_1 = adapter_1.request_device_sync(\n",
    "    required_features=[wgpu.FeatureName.timestamp_query]\n",
    ")\n",
    "pprint(adapter_1.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44f00dfe-b616-4717-8cdc-fbe186c31e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'adapter_type': 'IntegratedGPU',\n",
      " 'architecture': '',\n",
      " 'backend_type': 'Vulkan',\n",
      " 'description': '24.12.1 (AMD proprietary shader compiler)',\n",
      " 'device': 'AMD Radeon(TM) Graphics',\n",
      " 'device_id': 5761,\n",
      " 'vendor': 'AMD proprietary driver',\n",
      " 'vendor_id': 4098}\n"
     ]
    }
   ],
   "source": [
    "if 1:\n",
    "    adapter = adapter_0\n",
    "    device = device_0\n",
    "else:\n",
    "    adapter = adapter_1\n",
    "    device = device_1\n",
    "\n",
    "pprint(adapter.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7d8a2bd-6a7b-4a32-8791-63a8cee984fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y, z\n",
    "total_cells = 1024*16\n",
    "\n",
    "x0_cpu = np.zeros((total_cells,), dtype=np.float32)\n",
    "x1_cpu = np.zeros((total_cells,), dtype=np.float32)\n",
    "x2_cpu = np.zeros((total_cells,), dtype=np.float32)\n",
    "y_cpu = np.zeros((total_cells,), dtype=np.float32)\n",
    "\n",
    "x0_cpu[:] = (-1.0*np.arange(total_cells, dtype=np.float32) + 0.5) % 1.28490\n",
    "x1_cpu[:] = (-1.0*np.arange(total_cells, dtype=np.float32) - 0.2) % 0.847\n",
    "x2_cpu[:] = (-2.0*np.arange(total_cells, dtype=np.float32) - 1.2) % 4.1\n",
    "\n",
    "# Create buffer objects, input buffer is mapped.\n",
    "x0_gpu = device.create_buffer_with_data(data=x0_cpu.data, usage=wgpu.BufferUsage.STORAGE)\n",
    "x1_gpu = device.create_buffer_with_data(data=x1_cpu.data, usage=wgpu.BufferUsage.STORAGE)\n",
    "x2_gpu = device.create_buffer_with_data(data=x2_cpu.data, usage=wgpu.BufferUsage.STORAGE)\n",
    "y_gpu = device.create_buffer_with_data(\n",
    "    data=y_cpu.data,\n",
    "    usage=wgpu.BufferUsage.STORAGE | wgpu.BufferUsage.COPY_SRC\n",
    ")\n",
    "y_gpu_readback = device.create_buffer(\n",
    "    size=y_cpu.data.nbytes,\n",
    "    usage=wgpu.BufferUsage.MAP_READ | wgpu.BufferUsage.COPY_DST\n",
    ")\n",
    "\n",
    "\n",
    "# Setup layout and bindings\n",
    "binding_layouts = [\n",
    "    {\n",
    "        \"binding\": 0,\n",
    "        \"visibility\": wgpu.ShaderStage.COMPUTE,\n",
    "        \"buffer\": {\n",
    "            \"type\": wgpu.BufferBindingType.read_only_storage,\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"binding\": 1,\n",
    "        \"visibility\": wgpu.ShaderStage.COMPUTE,\n",
    "        \"buffer\": {\n",
    "            \"type\": wgpu.BufferBindingType.read_only_storage,\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"binding\": 2,\n",
    "        \"visibility\": wgpu.ShaderStage.COMPUTE,\n",
    "        \"buffer\": {\n",
    "            \"type\": wgpu.BufferBindingType.read_only_storage,\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"binding\": 3,\n",
    "        \"visibility\": wgpu.ShaderStage.COMPUTE,\n",
    "        \"buffer\": {\n",
    "            \"type\": wgpu.BufferBindingType.storage,\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "# Put everything together\n",
    "bind_group_layout = device.create_bind_group_layout(entries=binding_layouts)\n",
    "pipeline_layout = device.create_pipeline_layout(bind_group_layouts=[bind_group_layout])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d466803d-db6e-4695-b533-fc2008bead53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_cells=16384\n",
      "workgroup_size=64\n",
      "dispatch_size=256\n",
      "global_size=16384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 9711/262144 [00:10<04:19, 971.00it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exceeded timeout limit for sample collection\n",
      "Finished submitting commands\n",
      "Waiting for queue to finish\n",
      "Queue is flushed\n",
      "=== Loop metrics ===\n",
      "total_samples=9712\n",
      "loop_avg=1029.758 us\n",
      "loop_cell_rate=15.911 M/s\n",
      "loop_flops=8.146 GFlops\n",
      "=== Net metrics ===\n",
      "final_sync=0.000 us\n",
      "net_avg=1029.758 us\n",
      "net_cell_rate=15.911 M/s\n",
      "net_flops=8.146 GFlops\n",
      "=== GPU metrics ===\n",
      "gpu_delta_avg=1.348 us\n",
      "gpu_cell_rate=12150.964 M/s\n",
      "gpu_flops=6.221 TFlops\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# create shader\n",
    "workgroup_size = 64\n",
    "loop_count = 1\n",
    "dispatch_size = int(total_cells / (workgroup_size * loop_count))\n",
    "global_size = dispatch_size*workgroup_size*loop_count\n",
    "print(f\"total_cells={total_cells}\")\n",
    "print(f\"workgroup_size={workgroup_size}\")\n",
    "print(f\"dispatch_size={dispatch_size}\")\n",
    "print(f\"global_size={global_size}\")\n",
    "assert global_size == total_cells\n",
    "\n",
    "work_per_cell = 512\n",
    "flops_per_work = 1\n",
    "\n",
    "shader_source = f\"\"\"\n",
    "@group(0) @binding(0)\n",
    "var<storage,read> x0: array<f32>;\n",
    "\n",
    "@group(0) @binding(1)\n",
    "var<storage,read> x1: array<f32>;\n",
    "\n",
    "@group(0) @binding(2)\n",
    "var<storage,read> x2: array<f32>;\n",
    "\n",
    "@group(0) @binding(3)\n",
    "var<storage,read_write> y: array<f32>;\n",
    "\n",
    "@compute\n",
    "@workgroup_size({workgroup_size})\n",
    "fn main(@builtin(global_invocation_id) i0: vec3<u32>) {{\n",
    "    let i: u32 = i0.x*{loop_count};\n",
    "    for (var j: u32 = 0; j < {loop_count}; j = j+1) {{\n",
    "        let k: u32 = i+j;\n",
    "        var v: f32 = 0.0;\n",
    "        for (var l: u32 = 0; l < {work_per_cell}; l = l+1) {{\n",
    "            let v0: f32 = x0[k]*x1[k] + x2[k];\n",
    "            v += v0;\n",
    "        }}\n",
    "        y[k] = v;\n",
    "    }}\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "cshader = device.create_shader_module(code=shader_source)\n",
    "\n",
    "# Create and run the pipeline\n",
    "compute_pipeline = device.create_compute_pipeline(\n",
    "    layout=pipeline_layout,\n",
    "    compute={\"module\": cshader, \"entry_point\": \"main\"},\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "Create a QuerySet to store the 'beginning_of_pass' and 'end_of_pass' timestamps.\n",
    "Set the 'count' parameter to 2, as this set will contain 2 timestamps.\n",
    "\"\"\"\n",
    "# query_count = 6\n",
    "query_count = 2\n",
    "query_set = device.create_query_set(type=wgpu.QueryType.timestamp, count=query_count)\n",
    "\n",
    "query_buf = device.create_buffer(\n",
    "    size=8*query_set.count,\n",
    "    usage=wgpu.BufferUsage.QUERY_RESOLVE | wgpu.BufferUsage.COPY_SRC,\n",
    ")\n",
    "\n",
    "profile_gpu = True\n",
    "\n",
    "if profile_gpu:\n",
    "    timestamp_writes = {\n",
    "        \"query_set\": query_set,\n",
    "        \"beginning_of_pass_write_index\": 0,\n",
    "        \"end_of_pass_write_index\": 1,\n",
    "    }\n",
    "else:\n",
    "    timestamp_writes = None\n",
    "\n",
    "bindings = [\n",
    "    {\n",
    "        \"binding\": 0,\n",
    "        \"resource\": {\"buffer\": x0_gpu, \"offset\": 0, \"size\": x0_gpu.size},\n",
    "    },\n",
    "    {\n",
    "        \"binding\": 1,\n",
    "        \"resource\": {\"buffer\": x1_gpu, \"offset\": 0, \"size\": x1_gpu.size},\n",
    "    },\n",
    "    {\n",
    "        \"binding\": 2,\n",
    "        \"resource\": {\"buffer\": x2_gpu, \"offset\": 0, \"size\": x2_gpu.size},\n",
    "    },\n",
    "    {\n",
    "        \"binding\": 3,\n",
    "        \"resource\": {\"buffer\": y_gpu, \"offset\": 0, \"size\": y_gpu.size},\n",
    "    },\n",
    "]\n",
    "bind_group = device.create_bind_group(layout=bind_group_layout, entries=bindings)\n",
    "\n",
    "\n",
    "# Pass our QuerySet and the indices into it, where the timestamps will be written.\n",
    "gpu_samples = []\n",
    "max_samples = 8192*32\n",
    "min_samples = 16\n",
    "sampling_timeout_ms = 10000\n",
    "\n",
    "start_ns = time.time_ns()\n",
    "for sample_idx in tqdm(range(max_samples)):\n",
    "    command_encoder = device.create_command_encoder()\n",
    "    compute_pass_0 = command_encoder.begin_compute_pass(timestamp_writes=timestamp_writes)\n",
    "    compute_pass_0.set_pipeline(compute_pipeline)\n",
    "    compute_pass_0.set_bind_group(0, bind_group)\n",
    "    compute_pass_0.dispatch_workgroups(dispatch_size)\n",
    "    compute_pass_0.end()\n",
    "    \n",
    "    # Resolve our queries, and store the results in the destination buffer we created above.\n",
    "    if profile_gpu:\n",
    "        command_encoder.resolve_query_set(\n",
    "            query_set=query_set,\n",
    "            first_query=0,\n",
    "            query_count=query_count,\n",
    "            destination=query_buf,\n",
    "            destination_offset=0,\n",
    "        )\n",
    "        command_encoder.copy_buffer_to_buffer(\n",
    "            source=y_gpu,\n",
    "            source_offset=0,\n",
    "            destination=y_gpu_readback,\n",
    "            destination_offset=0,\n",
    "            size=y_cpu.data.nbytes\n",
    "        )\n",
    "    device.queue.submit([command_encoder.finish()])\n",
    "\n",
    "    if profile_gpu:\n",
    "        timestamps_ns = device.queue.read_buffer(query_buf).cast(\"Q\").tolist()\n",
    "        gpu_delta_ns = timestamps_ns[1] - timestamps_ns[0]\n",
    "        gpu_samples.append(gpu_delta_ns)\n",
    "    \n",
    "    total_ns = time.time_ns() - start_ns\n",
    "    if sample_idx >= min_samples and total_ns > sampling_timeout_ms*1e6:\n",
    "        print(\"Exceeded timeout limit for sample collection\")\n",
    "        break\n",
    "end_ns = time.time_ns()\n",
    "loop_ns = end_ns - start_ns\n",
    "print(\"Finished submitting commands\")\n",
    "\n",
    "print(\"Waiting for queue to finish\")\n",
    "start_ns = time.time_ns()\n",
    "device.queue.on_submitted_work_done_sync()\n",
    "end_ns = time.time_ns()\n",
    "final_sync_ns = end_ns - start_ns\n",
    "print(\"Queue is flushed\")\n",
    "\n",
    "total_samples = sample_idx + 1\n",
    "loop_ns_avg = loop_ns / total_samples\n",
    "loop_cell_rate = total_cells / (loop_ns_avg*1e-9)\n",
    "loop_flops = loop_cell_rate*work_per_cell*flops_per_work\n",
    "print(\"=== Loop metrics ===\")\n",
    "print(f\"total_samples={total_samples}\")\n",
    "print(f\"loop_avg={loop_ns_avg*1e-3:.3f} us\")\n",
    "print(f\"loop_cell_rate={loop_cell_rate*1e-6:.3f} M/s\")\n",
    "print(f\"loop_flops={loop_flops*1e-9:.3f} GFlops\")\n",
    "\n",
    "net_ns = loop_ns + final_sync_ns\n",
    "net_ns_avg = net_ns / total_samples\n",
    "net_cell_rate = total_cells / (net_ns_avg*1e-9)\n",
    "net_flops = net_cell_rate*work_per_cell*flops_per_work\n",
    "print(\"=== Net metrics ===\")\n",
    "print(f\"final_sync={final_sync_ns*1e-3:.3f} us\")\n",
    "print(f\"net_avg={net_ns_avg*1e-3:.3f} us\")\n",
    "print(f\"net_cell_rate={net_cell_rate*1e-6:.3f} M/s\")\n",
    "print(f\"net_flops={net_flops*1e-9:.3f} GFlops\")\n",
    "\n",
    "gpu_delta_ns = np.array(gpu_samples)\n",
    "gpu_delta_ns_avg = np.mean(gpu_delta_ns)\n",
    "gpu_cell_rate = total_cells / (gpu_delta_ns_avg*1e-9)\n",
    "gpu_flops = gpu_cell_rate*work_per_cell*flops_per_work\n",
    "\n",
    "print(\"=== GPU metrics ===\")\n",
    "print(f\"gpu_delta_avg={gpu_delta_ns_avg*1e-3:.3f} us\")\n",
    "print(f\"gpu_cell_rate={gpu_cell_rate*1e-6:.3f} M/s\")\n",
    "print(f\"gpu_flops={gpu_flops*1e-12:.3f} TFlops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f27246db-a3ae-4ced-80af-c350bbe15685",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_gpu_readback.map_sync(wgpu.MapMode.READ, 0, y_cpu.data.nbytes)\n",
    "y_cpu_calc_memview = y_gpu_readback.read_mapped(buffer_offset=0, size=y_cpu.data.nbytes, copy=True)\n",
    "y_cpu_calc = np.frombuffer(y_cpu_calc_memview, dtype=np.float32)\n",
    "y_cpu_calc = np.reshape(y_cpu_calc, (total_cells,))\n",
    "y_gpu_readback.unmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7581fcf9-25d0-4c81-8021-2f5af8095eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 2787/9712 [00:10<00:25, 275.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exceeded timeout limit for sample collection\n",
      "cpu_delta_avg=3587.706 us\n",
      "cpu_cell_rate=4.567 M/s\n",
      "cpu_flops=2.338 GFlops\n",
      "gpu/cpu = 2660.77x\n",
      "error_min=-1.782e-02\n",
      "error_max=1.733e-02\n",
      "error_avg=1.815e-05\n",
      "error_abs_avg=4.025e-03\n",
      "[1650.4315   659.32306 1722.7794   518.7187  1593.5553 ]\n",
      "[1650.4365  659.3222 1722.7683  518.7187 1593.5613]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def cpu_shader(x0, x1, x2, y):\n",
    "    for i in range(work_per_cell):\n",
    "        y[:] += (x0*x1 + x2)\n",
    "\n",
    "# Calculate the result on the CPU for comparison\n",
    "y_cpu_pred = np.zeros(y_cpu.shape, dtype=y_cpu.dtype)\n",
    "\n",
    "cpu_samples = []\n",
    "total_ns = 0\n",
    "for sample_idx in tqdm(range(total_samples)):\n",
    "    y_cpu_pred[:] = 0.0\n",
    "    start_ns = time.perf_counter_ns()\n",
    "    cpu_shader(x0_cpu, x1_cpu, x2_cpu, y_cpu_pred)\n",
    "    end_ns = time.perf_counter_ns()\n",
    "    delta_ns = end_ns - start_ns\n",
    "    cpu_samples.append(delta_ns)\n",
    "    total_ns += delta_ns\n",
    "    if sample_idx >= min_samples and total_ns > sampling_timeout_ms*1e6:\n",
    "        print(\"Exceeded timeout limit for sample collection\")\n",
    "        break\n",
    "    \n",
    "cpu_delta_ns = np.array(cpu_samples)\n",
    "cpu_delta_ns_avg = np.mean(cpu_delta_ns)\n",
    "print(f\"cpu_delta_avg={cpu_delta_ns_avg*1e-3:.3f} us\")\n",
    "cpu_cell_rate = total_cells / (cpu_delta_ns_avg*1e-9)\n",
    "print(f\"cpu_cell_rate={cpu_cell_rate*1e-6:.3f} M/s\")\n",
    "cpu_flops = cpu_cell_rate*work_per_cell*flops_per_work\n",
    "print(f\"cpu_flops={cpu_flops*1e-9:.3f} GFlops\")\n",
    "print(f\"gpu/cpu = {gpu_cell_rate/cpu_cell_rate:.2f}x\")\n",
    "\n",
    "\n",
    "# Ensure results are the same\n",
    "error = y_cpu_calc - y_cpu_pred\n",
    "error_abs = np.abs(error)\n",
    "error_avg = np.mean(error) \n",
    "error_max = np.max(error)\n",
    "error_min = np.min(error)\n",
    "error_abs_avg = np.mean(error_abs)\n",
    "\n",
    "print(f\"error_min={error_min:.3e}\")\n",
    "print(f\"error_max={error_max:.3e}\")\n",
    "print(f\"error_avg={error_avg:.3e}\")\n",
    "print(f\"error_abs_avg={error_abs_avg:.3e}\")\n",
    "\n",
    "n_read = 5\n",
    "print(y_cpu_calc[:n_read])\n",
    "print(y_cpu_pred[:n_read])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
