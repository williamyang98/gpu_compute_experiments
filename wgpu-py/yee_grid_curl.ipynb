{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4a30076-3ec0-4269-873a-da992ff94397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wgpu\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import torch_directml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50669a62-ac40-4252-bf8b-afc3e802efcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'adapter_type': 'IntegratedGPU',\n",
      " 'architecture': '',\n",
      " 'backend_type': 'Vulkan',\n",
      " 'description': '24.12.1 (AMD proprietary shader compiler)',\n",
      " 'device': 'AMD Radeon(TM) Graphics',\n",
      " 'device_id': 5761,\n",
      " 'vendor': 'AMD proprietary driver',\n",
      " 'vendor_id': 4098}\n",
      "{'adapter_type': 'IntegratedGPU',\n",
      " 'architecture': '',\n",
      " 'backend_type': 'Vulkan',\n",
      " 'description': '24.12.1 (AMD proprietary shader compiler)',\n",
      " 'device': 'AMD Radeon(TM) Graphics',\n",
      " 'device_id': 5761,\n",
      " 'vendor': 'AMD proprietary driver',\n",
      " 'vendor_id': 4098}\n"
     ]
    }
   ],
   "source": [
    "adapter_0 = wgpu.gpu.request_adapter_sync(power_preference=\"high-performance\")\n",
    "device_0 = adapter_0.request_device_sync(\n",
    "    required_features=[wgpu.FeatureName.timestamp_query]\n",
    ")\n",
    "pprint(adapter_0.info)\n",
    "\n",
    "adapter_1 = wgpu.gpu.request_adapter_sync(power_preference=\"low-power\")\n",
    "device_1 = adapter_1.request_device_sync(\n",
    "    required_features=[wgpu.FeatureName.timestamp_query]\n",
    ")\n",
    "pprint(adapter_1.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "537b5040-f332-4fd5-9355-60bbb65c3580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'adapter_type': 'IntegratedGPU',\n",
      " 'architecture': '',\n",
      " 'backend_type': 'Vulkan',\n",
      " 'description': '24.12.1 (AMD proprietary shader compiler)',\n",
      " 'device': 'AMD Radeon(TM) Graphics',\n",
      " 'device_id': 5761,\n",
      " 'vendor': 'AMD proprietary driver',\n",
      " 'vendor_id': 4098}\n"
     ]
    }
   ],
   "source": [
    "if 0:\n",
    "    adapter = adapter_0\n",
    "    device = device_0\n",
    "else:\n",
    "    adapter = adapter_1\n",
    "    device = device_1\n",
    "\n",
    "pprint(adapter.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d189c076-4bc4-444c-8bc6-3176672ee608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_size=[32, 128, 1024]\n",
      "total_cells=4194304\n"
     ]
    }
   ],
   "source": [
    "# x, y, z\n",
    "grid_size = [32, 128, 1024]\n",
    "#grid_size = [17, 107, 152]\n",
    "total_cells = grid_size[0]*grid_size[1]*grid_size[2]\n",
    "\n",
    "print(f\"grid_size={grid_size}\")\n",
    "print(f\"total_cells={total_cells}\")\n",
    "\n",
    "# create cpu side data\n",
    "n_dims = 3\n",
    "x_cpu = np.zeros(grid_size + [n_dims,], dtype=np.float32)\n",
    "y_cpu = np.zeros(grid_size + [n_dims,], dtype=np.float32)\n",
    "\n",
    "x = np.reshape(x_cpu, (n_dims*total_cells,))\n",
    "x[:] = (-1.0*np.arange(0, n_dims*total_cells, dtype=np.float32) + 0.5) % 0.88490\n",
    "\n",
    "# Create buffer objects, input buffer is mapped.\n",
    "x_gpu = device.create_buffer_with_data(data=x_cpu.data, usage=wgpu.BufferUsage.STORAGE)\n",
    "y_gpu = device.create_buffer_with_data(\n",
    "    data=y_cpu.data,\n",
    "    usage=wgpu.BufferUsage.STORAGE | wgpu.BufferUsage.COPY_SRC\n",
    ")\n",
    "y_gpu_readback = device.create_buffer(\n",
    "    size=y_cpu.data.nbytes,\n",
    "    usage=wgpu.BufferUsage.MAP_READ | wgpu.BufferUsage.COPY_DST\n",
    ")\n",
    "\n",
    "# Setup layout and bindings\n",
    "binding_layouts = [\n",
    "    {\n",
    "        \"binding\": 0,\n",
    "        \"visibility\": wgpu.ShaderStage.COMPUTE,\n",
    "        \"buffer\": {\n",
    "            \"type\": wgpu.BufferBindingType.read_only_storage,\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"binding\": 1,\n",
    "        \"visibility\": wgpu.ShaderStage.COMPUTE,\n",
    "        \"buffer\": {\n",
    "            \"type\": wgpu.BufferBindingType.storage,\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "# Put everything together\n",
    "bind_group_layout = device.create_bind_group_layout(entries=binding_layouts)\n",
    "pipeline_layout = device.create_pipeline_layout(bind_group_layouts=[bind_group_layout])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77764034-aa26-4b4e-a0c2-a7fde9e13250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### SEARCH ###\n",
      "local_size=[1, 4, 64]\n",
      "dispatch_size=[32, 32, 16]\n",
      "grid_size=[32, 128, 1024]\n",
      "global_size=[32, 128, 1024]\n",
      "Exceeded timeout limit for sample collection\n",
      "cell_count=4194304\n",
      "gpu_delta_avg=368.223 us\n",
      "gpu_cell_rate=11390.658 M/s\n",
      "total_samples=14\n",
      "gpu_flops=136.688 GFlops\n"
     ]
    }
   ],
   "source": [
    "# create shader\n",
    "# local_size = [1, 8, 128]\n",
    "local_size = [1, 4, 64]\n",
    "dispatch_size = [math.ceil(g/l) for g,l in zip(grid_size, local_size)]\n",
    "global_size = [d*l for d,l in zip(dispatch_size, local_size)]\n",
    "flops_per_cell = 12\n",
    "\n",
    "print(\"### SEARCH ###\")\n",
    "print(f\"local_size={local_size}\")\n",
    "print(f\"dispatch_size={dispatch_size}\")\n",
    "print(f\"grid_size={grid_size}\")\n",
    "print(f\"global_size={global_size}\")\n",
    "#assert(global_size == grid_size)\n",
    "\n",
    "shader_source = f\"\"\"\n",
    "@group(0) @binding(0)\n",
    "var<storage,read> x: array<f32>;\n",
    "\n",
    "@group(0) @binding(1)\n",
    "var<storage,read_write> y: array<f32>;\n",
    "\n",
    "fn get_offset(i: vec3<u32>) -> u32 {{\n",
    "    let x: u32 = i.x % {grid_size[0]};\n",
    "    let y: u32 = i.y % {grid_size[1]};\n",
    "    let z: u32 = i.z % {grid_size[2]};\n",
    "    let offset: u32 = z + y*{grid_size[2]} + x*{grid_size[2]*grid_size[1]};\n",
    "    return offset*{n_dims};\n",
    "}}\n",
    "\n",
    "@compute\n",
    "@workgroup_size({\",\".join(map(str, local_size))})\n",
    "fn main(@builtin(global_invocation_id) i0: vec3<u32>) {{\n",
    "    if (i0.x >= {grid_size[0]}) {{ return; }}\n",
    "    if (i0.y >= {grid_size[1]}) {{ return; }}\n",
    "    if (i0.z >= {grid_size[2]}) {{ return; }}\n",
    "    let i = get_offset(i0);\n",
    "    let iz = get_offset(i0 + vec3(0,0,1));\n",
    "    let iy = get_offset(i0 + vec3(0,1,0));\n",
    "    let ix = get_offset(i0 + vec3(1,0,0));\n",
    "    y[i+0] += (x[i+2]-x[iy+2]) - (x[i+1]-x[iz+1]);\n",
    "    y[i+1] += (x[i+0]-x[iz+0]) - (x[i+2]-x[ix+2]);\n",
    "    y[i+2] += (x[i+1]-x[ix+1]) - (x[i+0]-x[iy+0]);\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "cshader = device.create_shader_module(code=shader_source)\n",
    "\n",
    "# Create and run the pipeline\n",
    "compute_pipeline = device.create_compute_pipeline(\n",
    "    layout=pipeline_layout,\n",
    "    compute={\"module\": cshader, \"entry_point\": \"main\"},\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "Create a QuerySet to store the 'beginning_of_pass' and 'end_of_pass' timestamps.\n",
    "Set the 'count' parameter to 2, as this set will contain 2 timestamps.\n",
    "\"\"\"\n",
    "# query_count = 6\n",
    "query_count = 2\n",
    "query_set = device.create_query_set(type=wgpu.QueryType.timestamp, count=query_count)\n",
    "\n",
    "\"\"\"\n",
    "Create the buffer to store our query results.\n",
    "Each timestamp is 8 bytes. We mark the buffer usage to be QUERY_RESOLVE,\n",
    "as we will use this buffer in a resolve_query_set call later.\n",
    "\"\"\"\n",
    "query_buf = device.create_buffer(\n",
    "    size=8*query_set.count,\n",
    "    usage=wgpu.BufferUsage.QUERY_RESOLVE | wgpu.BufferUsage.COPY_SRC,\n",
    ")\n",
    "\n",
    "# Pass our QuerySet and the indices into it, where the timestamps will be written.\n",
    "gpu_samples = []\n",
    "total_ns = 0\n",
    "max_samples = 128\n",
    "min_samples = 3\n",
    "sampling_timeout_ms = 5\n",
    "\n",
    "for sample_idx in range(max_samples):\n",
    "    command_encoder = device.create_command_encoder()\n",
    "    \n",
    "    compute_pass_0 = command_encoder.begin_compute_pass(\n",
    "        timestamp_writes={\n",
    "            \"query_set\": query_set,\n",
    "            \"beginning_of_pass_write_index\": 0,\n",
    "            \"end_of_pass_write_index\": 1,\n",
    "        }\n",
    "    )\n",
    "    compute_pass_0.set_pipeline(compute_pipeline)\n",
    "    bindings = [\n",
    "        {\n",
    "            \"binding\": 0,\n",
    "            \"resource\": {\"buffer\": x_gpu, \"offset\": 0, \"size\": x_gpu.size},\n",
    "        },\n",
    "        {\n",
    "            \"binding\": 1,\n",
    "            \"resource\": {\"buffer\": y_gpu, \"offset\": 0, \"size\": y_gpu.size},\n",
    "        },\n",
    "    ]\n",
    "    bind_group = device.create_bind_group(layout=bind_group_layout, entries=bindings)\n",
    "    compute_pass_0.set_bind_group(0, bind_group)\n",
    "    compute_pass_0.dispatch_workgroups(*dispatch_size)  # x y z\n",
    "    compute_pass_0.end()\n",
    "    \n",
    "    # Resolve our queries, and store the results in the destination buffer we created above.\n",
    "    command_encoder.resolve_query_set(\n",
    "        query_set=query_set,\n",
    "        first_query=0,\n",
    "        query_count=query_count,\n",
    "        destination=query_buf,\n",
    "        destination_offset=0,\n",
    "    )\n",
    "    command_encoder.copy_buffer_to_buffer(\n",
    "        source=y_gpu,\n",
    "        source_offset=0,\n",
    "        destination=y_gpu_readback,\n",
    "        destination_offset=0,\n",
    "        size=y_cpu.data.nbytes\n",
    "    )\n",
    "    device.queue.submit([command_encoder.finish()])\n",
    "    \n",
    "    \"\"\"\n",
    "    Read the query buffer to get the timestamps.\n",
    "    Index 0: beginning timestamp\n",
    "    Index 1: end timestamp\n",
    "    \"\"\"\n",
    "    timestamps_ns = device.queue.read_buffer(query_buf).cast(\"Q\").tolist()\n",
    "    delta_ns = timestamps_ns[1] - timestamps_ns[0]\n",
    "    gpu_samples.append(delta_ns)\n",
    "    total_ns += delta_ns\n",
    "    if sample_idx >= min_samples and total_ns > sampling_timeout_ms*1e6:\n",
    "        print(\"Exceeded timeout limit for sample collection\")\n",
    "        break\n",
    "\n",
    "gpu_delta_ns = np.array(gpu_samples)\n",
    "gpu_delta_ns_avg = np.mean(gpu_delta_ns)\n",
    "print(f\"cell_count={total_cells}\")\n",
    "print(f\"gpu_delta_avg={gpu_delta_ns_avg*1e-3:.3f} us\")\n",
    "gpu_cell_rate = total_cells / (gpu_delta_ns_avg*1e-9)\n",
    "print(f\"gpu_cell_rate={gpu_cell_rate*1e-6:.3f} M/s\")\n",
    "print(f\"total_samples={len(gpu_samples)}\")\n",
    "gpu_flops = flops_per_cell*gpu_cell_rate\n",
    "print(f\"gpu_flops={gpu_flops*1e-9:.3f} GFlops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaf51331-d6f2-4bf1-88d4-ee7f4dc5dca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read result\n",
    "y_gpu_readback.map_sync(wgpu.MapMode.READ, 0, y_cpu.data.nbytes)\n",
    "y_gpu_pred_memview = y_gpu_readback.read_mapped(buffer_offset=0, size=y_cpu.data.nbytes, copy=True)\n",
    "y_gpu_pred = np.frombuffer(y_gpu_pred_memview, dtype=np.float32)\n",
    "y_gpu_pred = np.reshape(y_gpu_pred, grid_size+[n_dims,])\n",
    "y_gpu_readback.unmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e72a27a-9642-48da-8919-de1de6b390d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu_delta_avg=83240.843 us\n",
      "cpu_cell_rate=50.388 M/s\n",
      "cpu_flops=0.605 GFlops\n",
      "gpu/cpu = 226.06x\n",
      "error_min=-5.722e-06\n",
      "error_max=5.722e-06\n",
      "error_avg=1.376e-07\n",
      "error_abs_avg=4.631e-07\n",
      "[[[[-10.052131    3.7448397   6.307289 ]]]]\n",
      "[[[[-10.052131   3.74484    6.307289]]]]\n",
      "[[[[-2.3594213  1.2679145 -9.685694 ]]]]\n",
      "[[[[-2.3594213  1.2679145 -9.685691 ]]]]\n"
     ]
    }
   ],
   "source": [
    "def cpu_shader(x, y, wrap_around=True):\n",
    "    if not wrap_around:\n",
    "        y[:,:-1,:-1,0] += (x[:,:-1,:-1,2]-x[:,1:,:-1,2]) - (x[:,:-1,:-1,1]-x[:,:-1,1:,1])\n",
    "        y[:-1,:,:-1,1] += (x[:-1,:,:-1,0]-x[:-1,:,1:,0]) - (x[:-1,:,:-1,2]-x[1:,:,:-1,2])\n",
    "        y[:-1,:-1,:,2] += (x[:-1,:-1,:,1]-x[1:,:-1,:,1]) - (x[:-1,:-1,:,0]-x[:-1,1:,:,0])\n",
    "    else:\n",
    "        y[:,:-1,:,0] += (x[:,:-1,:,2]-x[:,1:,:,2]) \n",
    "        y[:,-1,:,0] += (x[:,-1,:,2]-x[:,0,:,2])\n",
    "        y[:,:,:-1,0] -= (x[:,:,:-1,1]-x[:,:,1:,1])\n",
    "        y[:,:,-1,0] -= (x[:,:,-1,1]-x[:,:,0,1])\n",
    "        \n",
    "        y[:,:,:-1,1] += (x[:,:,:-1,0]-x[:,:,1:,0]) \n",
    "        y[:,:,-1,1] += (x[:,:,-1,0]-x[:,:,0,0]) \n",
    "        y[:-1,:,:,1] -= (x[:-1,:,:,2]-x[1:,:,:,2])\n",
    "        y[-1,:,:,1] -= (x[-1,:,:,2]-x[0,:,:,2])\n",
    "        \n",
    "        y[:-1,:,:,2] += (x[:-1,:,:,1]-x[1:,:,:,1]) \n",
    "        y[-1,:,:,2] += (x[-1,:,:,1]-x[0,:,:,1]) \n",
    "        y[:,:-1,:,2] -= (x[:,:-1,:,0]-x[:,1:,:,0])\n",
    "        y[:,-1,:,2] -= (x[:,-1,:,0]-x[:,0,:,0])\n",
    "\n",
    "# Calculate the result on the CPU for comparison\n",
    "y_cpu_pred = np.zeros(y_cpu.shape, dtype=y_cpu.dtype)\n",
    "\n",
    "cpu_samples = []\n",
    "for _ in range(len(gpu_samples)):\n",
    "    start_ns = time.perf_counter_ns()\n",
    "    cpu_shader(x_cpu, y_cpu_pred, wrap_around=True)\n",
    "    end_ns = time.perf_counter_ns()\n",
    "    delta_ns = end_ns - start_ns\n",
    "    cpu_samples.append(delta_ns)\n",
    "cpu_delta_ns = np.array(cpu_samples)\n",
    "cpu_delta_ns_avg = np.mean(cpu_delta_ns)\n",
    "cpu_cell_rate = total_cells / (cpu_delta_ns_avg*1e-9)\n",
    "cpu_flops = cpu_cell_rate*flops_per_cell\n",
    "print(f\"cpu_delta_avg={cpu_delta_ns_avg*1e-3:.3f} us\")\n",
    "print(f\"cpu_cell_rate={cpu_cell_rate*1e-6:.3f} M/s\")\n",
    "print(f\"cpu_flops={cpu_flops*1e-9:.3f} GFlops\")\n",
    "print(f\"gpu/cpu = {gpu_cell_rate/cpu_cell_rate:.2f}x\")\n",
    "\n",
    "# Ensure results are the same\n",
    "error = y_gpu_pred - y_cpu_pred\n",
    "#error = error[:-1,:-1,:-1,:] # skip last dimension on curl\n",
    "error_max = np.max(error)\n",
    "error_min = np.min(error)\n",
    "error_abs = np.abs(error)\n",
    "error_avg = np.mean(error) \n",
    "error_abs_avg = np.mean(error_abs)\n",
    "\n",
    "print(f\"error_min={error_min:.3e}\")\n",
    "print(f\"error_max={error_max:.3e}\")\n",
    "print(f\"error_avg={error_avg:.3e}\")\n",
    "print(f\"error_abs_avg={error_abs_avg:.3e}\")\n",
    "\n",
    "n_read = 1\n",
    "print(y_gpu_pred[:n_read, :n_read, :n_read, :])\n",
    "print(y_cpu_pred[:n_read, :n_read, :n_read, :])\n",
    "print(y_gpu_pred[-n_read:, -n_read:, -n_read:,:])\n",
    "print(y_cpu_pred[-n_read:, -n_read:, -n_read:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d74f9e36-abc1-4e83-87af-c2bf8b39d94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch_cpu_delta_avg=36977.993 us\n",
      "torch_cpu_cell_rate=113.427 M/s\n",
      "torch_cpu_flops=1.361 GFlops\n",
      "gpu/torch_cpu = 100.42x\n",
      "error_min=-5.722e-06\n",
      "error_max=5.722e-06\n",
      "error_avg=1.376e-07\n",
      "error_abs_avg=4.631e-07\n",
      "[[[[-10.052131    3.7448397   6.307289 ]]]]\n",
      "[[[[-10.052131   3.74484    6.307289]]]]\n",
      "[[[[-2.3594213  1.2679145 -9.685694 ]]]]\n",
      "[[[[-2.3594213  1.2679145 -9.685691 ]]]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the result on the CPU for comparison\n",
    "torch_device = \"cpu\"\n",
    "x_torch_cpu = torch.zeros(*x_cpu.shape, dtype=torch.float32, device=torch_device)\n",
    "y_torch_cpu_pred = torch.zeros(*y_cpu.shape, dtype=torch.float32, device=torch_device)\n",
    "x_torch_cpu.copy_(torch.from_numpy(x_cpu))\n",
    "\n",
    "torch_cpu_samples = []\n",
    "for _ in range(len(gpu_samples)):\n",
    "    start_ns = time.perf_counter_ns()\n",
    "    cpu_shader(x_torch_cpu, y_torch_cpu_pred, wrap_around=True)\n",
    "    end_ns = time.perf_counter_ns()\n",
    "    delta_ns = end_ns - start_ns\n",
    "    torch_cpu_samples.append(delta_ns)\n",
    "torch_cpu_delta_ns = np.array(torch_cpu_samples)\n",
    "torch_cpu_delta_ns_avg = np.mean(torch_cpu_delta_ns)\n",
    "torch_cpu_cell_rate = total_cells / (torch_cpu_delta_ns_avg*1e-9)\n",
    "torch_cpu_flops = torch_cpu_cell_rate*flops_per_cell\n",
    "print(f\"torch_cpu_delta_avg={torch_cpu_delta_ns_avg*1e-3:.3f} us\")\n",
    "print(f\"torch_cpu_cell_rate={torch_cpu_cell_rate*1e-6:.3f} M/s\")\n",
    "print(f\"torch_cpu_flops={torch_cpu_flops*1e-9:.3f} GFlops\")\n",
    "print(f\"gpu/torch_cpu = {gpu_cell_rate/torch_cpu_cell_rate:.2f}x\")\n",
    "\n",
    "y_torch_cpu_pred = y_torch_cpu_pred.numpy()\n",
    "\n",
    "# Ensure results are the same\n",
    "error = y_gpu_pred - y_torch_cpu_pred\n",
    "#error = error[:-1,:-1,:-1,:] # skip last dimension on curl\n",
    "error_max = np.max(error)\n",
    "error_min = np.min(error)\n",
    "error_abs = np.abs(error)\n",
    "error_avg = np.mean(error) \n",
    "error_abs_avg = np.mean(error_abs)\n",
    "\n",
    "print(f\"error_min={error_min:.3e}\")\n",
    "print(f\"error_max={error_max:.3e}\")\n",
    "print(f\"error_avg={error_avg:.3e}\")\n",
    "print(f\"error_abs_avg={error_abs_avg:.3e}\")\n",
    "\n",
    "n_read = 1\n",
    "print(y_gpu_pred[:n_read, :n_read, :n_read, :])\n",
    "print(y_torch_cpu_pred[:n_read, :n_read, :n_read, :])\n",
    "print(y_gpu_pred[-n_read:, -n_read:, -n_read:,:])\n",
    "print(y_torch_cpu_pred[-n_read:, -n_read:, -n_read:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "349c474c-ad58-40be-ba88-20d306c74036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch_gpu_delta_avg=421550.671 us\n",
      "torch_gpu_cell_rate=9.950 M/s\n",
      "torch_gpu_flops=0.119 GFlops\n",
      "gpu/torch_gpu = 1144.82x\n",
      "error_min=-5.722e-06\n",
      "error_max=3.338e-06\n",
      "error_avg=1.334e-07\n",
      "error_abs_avg=4.592e-07\n",
      "[[[[-10.052131    3.7448397   6.307289 ]]]]\n",
      "[[[[-10.052131   3.74484    6.307289]]]]\n",
      "[[[[-2.3594213  1.2679145 -9.685694 ]]]]\n",
      "[[[[ 0.         -0.72506833  0.        ]]]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the result on the CPU for comparison\n",
    "TORCH_DIRECTML_DEVICE = torch_directml.device(0)\n",
    "torch_device = TORCH_DIRECTML_DEVICE\n",
    "x_torch_gpu = torch.zeros(*x_cpu.shape, dtype=torch.float32, device=torch_device)\n",
    "y_torch_gpu_pred = torch.zeros(*y_cpu.shape, dtype=torch.float32, device=torch_device)\n",
    "x_torch_gpu.copy_(torch.from_numpy(x_cpu))\n",
    "\n",
    "torch_gpu_samples = []\n",
    "for _ in range(len(gpu_samples)):\n",
    "    start_ns = time.perf_counter_ns()\n",
    "    cpu_shader(x_torch_gpu, y_torch_gpu_pred, wrap_around=True)\n",
    "    end_ns = time.perf_counter_ns()\n",
    "    delta_ns = end_ns - start_ns\n",
    "    torch_gpu_samples.append(delta_ns)\n",
    "torch_gpu_delta_ns = np.array(torch_gpu_samples)\n",
    "torch_gpu_delta_ns_avg = np.mean(torch_gpu_delta_ns)\n",
    "torch_gpu_cell_rate = total_cells / (torch_gpu_delta_ns_avg*1e-9)\n",
    "torch_gpu_flops = torch_gpu_cell_rate*flops_per_cell\n",
    "print(f\"torch_gpu_delta_avg={torch_gpu_delta_ns_avg*1e-3:.3f} us\")\n",
    "print(f\"torch_gpu_cell_rate={torch_gpu_cell_rate*1e-6:.3f} M/s\")\n",
    "print(f\"torch_gpu_flops={torch_gpu_flops*1e-9:.3f} GFlops\")\n",
    "print(f\"gpu/torch_gpu = {gpu_cell_rate/torch_gpu_cell_rate:.2f}x\")\n",
    "\n",
    "y_torch_gpu_pred = y_torch_gpu_pred.cpu().numpy()\n",
    "\n",
    "# Ensure results are the same\n",
    "error = y_gpu_pred - y_torch_gpu_pred\n",
    "error = error[:-1,:-1,:-1,:] # skip last dimension on curl\n",
    "error_max = np.max(error)\n",
    "error_min = np.min(error)\n",
    "error_abs = np.abs(error)\n",
    "error_avg = np.mean(error) \n",
    "error_abs_avg = np.mean(error_abs)\n",
    "\n",
    "print(f\"error_min={error_min:.3e}\")\n",
    "print(f\"error_max={error_max:.3e}\")\n",
    "print(f\"error_avg={error_avg:.3e}\")\n",
    "print(f\"error_abs_avg={error_abs_avg:.3e}\")\n",
    "\n",
    "n_read = 1\n",
    "print(y_gpu_pred[:n_read, :n_read, :n_read, :])\n",
    "print(y_torch_gpu_pred[:n_read, :n_read, :n_read, :])\n",
    "print(y_gpu_pred[-n_read:, -n_read:, -n_read:,:])\n",
    "print(y_torch_gpu_pred[-n_read:, -n_read:, -n_read:,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
